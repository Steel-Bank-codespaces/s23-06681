{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Intermediate Pandas\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Today we look at some ways to use Pandas DataFrames like databases. It is much more convenient to do this with Pandas than numpy arrays, but it means learning a lot more stuff.\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Revisiting a previous example with batches of data\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We start with the example we looked at before. It is a dataset from a set of experiments. The experiments are grouped by the Day they were run on. We will use Pandas to do some analysis by the day.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "df = pd.read_csv('p-t.dat', delimiter='\\s+', skiprows=2,\n", "                 names=['Run order', 'Day', 'Ambient Temperature', 'Temperature',\n", "                        'Pressure', 'Fitted Value', 'Residual'])\n", "df\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Suppose we want to get information about different days. Let's do some work by hand.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['Day'] == 1\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can get all kinds of data on this.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[df['Day'] == 1].describe()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can use a list comprehension to loop over the days and get an average for each one.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["[df[df['Day'] == x].mean() for x in [1, 2, 3, 4]]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It is a little inconvenient to have to know all the days. We can get them from the dataframe itself.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['Day'].unique()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, we can put it all together to get the mean of a single column grouped by day.\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["[df[df['Day'] == x]['Temperature'].mean() for x in df['Day'].unique()]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["That was an exploratory approach that was somewhat motivated by the approach we would use in Numpy.  Next, we look at the Pandas way.\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The first aggregation we will look at is how to make groups of data that are related by values in a column.  We use the `groupby` function ([https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby)), and specify a column to group on. The result is a `DataFrameGroupBy` object, which we next have to work with.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["groups = df.groupby('Day')\n", "type(groups)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The groups can describe themselves. Here we see we get 4 groups, one for each day, and you can see some statistics about each group. We do not need those for now.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["groups.describe()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can get a dictionary of the group names and labels from the groups attribute.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["groups.groups\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can get the subset of rows from those group labels.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[groups.groups[2]]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We don't usually work with groups that way though, it is more common to do some analysis on each group.\n", "\n", "Suppose we want to plot the Pressure vs Temperature for each group, so we can see visually if there are any trends that could be attributed to the group. To do this, we need to *iterate* over the groups and then make a plot on each one.\n", "\n", "A `DataFrameGroupBy` is *iterable* and when you loop over it, you get the `key` it was grouped on, and a DataFrame that contains the items in the group. Here we loop over each group, and plot each group with a different color.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "fig, ax = plt.subplots()\n", "for (day, group) in groups:\n", "    group.plot('Temperature', 'Pressure', ax=ax, label=f'{day}', style='o')\n", "plt.ylabel('Pressure');\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["the point of this is we cannot see a visual clustering of the groups by day. That is important, because if we did it could suggest something was different that day.\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Combining data sets\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Siddhant Lambor provided from two experiments conducted to measure the properties of a worm-like micelles solution. He had carried out experiments on a rheometer to measure the viscosity of a worm-like micelles solution in a Couette cell geometry and a Cone and Plate geometry. Ideally, there should not be a difference as viscosity is intrinsic to the fluid. Analysis of this data will confirm if that is true. First, we read this data in from the two data files.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["couette = pd.read_excel('couette.xls',\n", "                   sheet_name='Flow sweep - 1',\n", "                   header=1) # sheet name is case sensitive, excel file name is not\n", "\n", "couette\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can drop the row at index 0, it just has the units in it. With this syntax, we have to save the resulting DataFrame back into the variable, or it will not be changed.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["couette = couette.drop(0)\n", "couette\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["There is a second file called cp.xls we want to combine with this. Here, we combine the drop function all into one line.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conePlate = pd.read_excel('cp.xls', sheet_name='Flow sweep - 1', header=1).drop(0)\n", "conePlate.head(5)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For this analysis, we are only interested in the shear rate, stress and viscosity values. Let us drop the other columns. We do that by the names, and specify inplace=True, which modifies the DataFrame itself.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conePlate.drop(['Temperature', 'Step time', 'Normal stress'], axis=1, inplace=True)\n", "# if we do not use inplace=True, the data frame will not be changed. It would by default create a new data frame\n", "# and we would have to assign a different variable to capture this change.\n", "conePlate.head(5)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We also do that for the couette data. Here we did not use `inplace=True`, so we have to save the result back into the variable to get the change.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["couette = couette.drop(['Temperature', 'Step time', 'Normal stress'], axis=1)   # without using inplace = True\n", "couette.head(5)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can see info about each DataFrame like this.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["couette.info()\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conePlate.info()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We could proceed to analyze the DataFrames separately, but instead, we will combine them into one DataFrame. Before doing that, we need to add a column to each one so we know which data set is which. Simply assigning a value to a new column name will do that.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["couette['type'] = 'couette'\n", "couette\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conePlate['type'] = 'cone'\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now, we can combine these into a single DataFrame. This is not critical, and you can get by without it, but I want to explore the idea, and illustrate it is possible.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.concat([conePlate, couette])\n", "df\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, we are ready for the visualization. We will group the DataFrame and then make plots for each group. Here we illustrate several new arguments, including loglog plots, secondary axes, colored tick labels, and multiple legends.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["g = df.groupby('type')\n", "ax1 = g.get_group('cone').plot('Shear rate', 'Viscosity',\n", "                               logx=True, logy=True, style='b.-',\n", "                               label=\"CP viscosity\")\n", "\n", "g.get_group('couette').plot('Shear rate', 'Viscosity', logx=True, logy=True,\n", "                            style='g.-', ax=ax1, label=\"Couette viscosity\")\n", "\n", "ax2 = g.get_group('cone').plot('Shear rate', 'Stress', secondary_y=True,\n", "                               logx=True, logy=True, style='r.-',\n", "                               ax=ax1, label=\"CP stress\")\n", "\n", "g.get_group('couette').plot('Shear rate', 'Stress', secondary_y=True,\n", "                            logx=True, logy = True, style='y.', ax=ax2,\n", "                            label=\"Couette Stress\")\n", "\n", "# Setting y axis labels\n", "ax1.set_ylabel(\"Viscosity (Pa.s)\", color='b')\n", "[ticklabel.set_color('b') for ticklabel in ax1.get_yticklabels()]\n", "\n", "ax2.set_ylabel(\"Stress (Pa)\", color='r')\n", "[ticklabel.set_color('r') for ticklabel in ax1.get_yticklabels()]\n", "\n", "# setting legend locations\n", "ax1.legend(loc=6)\n", "ax2.legend(loc=7)\n", "\n", "ax1.set_xlabel(\"Shear rate (1/s)\")\n", "plt.title(\"Comparison of Cone and Plate with Couette Cell\")\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["So, in fact we can see these two experiments are practically equivalent.\n", "\n", "\n", "\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.7"}, "org": null, "widgets": {"application/vnd.jupyter.widget-state+json": {"state": {}, "version_major": 2, "version_minor": 0}}}, "nbformat": 4, "nbformat_minor": 4}