{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["## Introduction to Pandas\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Before we jump into Pandas, let us review what we have considered so far.\n", "\n", "First, we learned how to read data from files into numpy arrays. We learned how to use variables to store that data, and to either slice the array into a few variables, or use slices themselves for something. We also learned how to make a *record* array that enabled us to access columns of the array by a *name*.\n", "\n", "When we loaded a json file, we got a *dictionary* data structure, which also allowed us to access data by a *name*.\n", "\n", "Second, we imported a visualization library, and made plots that used the arrays as arguments.\n", "\n", "For \"small\" data sets, i.e. not too many columns, this is a perfectly reasonable thing to do. For larger datasets, however, it can be tedious to create a lot of variable names, and it is also hard to remember what is in each column.\n", "\n", "Many tasks are pretty standard, e.g. read a data set, summarize and visualize it. It would be nice if we had a simple way to do this, with few lines of code, since those lines will be the same every time.\n", "\n", "The [Pandas](https://pandas.pydata.org/) library was developed to address all these issues. From the website: \"**pandas** is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\"\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Review of the numpy array way\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's review what we learned already.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "data = np.loadtxt('raman.txt')\n", "\n", "wavenumber, intensity = data.T  # the transpose has data in rows for unpacking\n", "ind = (wavenumber >= 1000) & (wavenumber < 1500)\n", "\n", "import matplotlib.pyplot as plt\n", "plt.figure()\n", "plt.plot(wavenumber[ind], intensity[ind])\n", "plt.xlabel('Wavenumber')\n", "plt.ylabel('Intensity');\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Now, with Pandas\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We will unpack this code shortly. For now, look how short it is to create this plot. Note that we have condensed all the code in the example above basically into three lines of code. That is pretty remarkable, but should give you some pause. We now have to learn how to use such a dense syntax!\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "\n", "df = pd.read_csv('raman.txt', delimiter = '\\t', index_col=0,\n", "                 names=['wavenumber', 'intensity'])\n", "df[(df.index >= 1000) & (df.index<1500)].plot();\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And to summarize.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What is the benefit of this dense syntax? Because it is so short, it is faster to type (at least, when you know what to type). That means it is also faster for you to read.\n", "\n", "The downside is that it is like learning a whole new language within Python, and a new mental model for how the data is stored and accessed. You have to decide if it is worthwhile doing that. If you do this a lot, it is probably worthwhile.\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Pandas\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The main object we will work with is called a `DataFrame`.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["type(df)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Jupyter notebooks can show you a fancy rendering of your dataframe.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The dataframe combines a few ideas we used from arrays and dictionaries. First, we can access a column by name. When we do this, we get a `Series` object.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["type(df['intensity'])\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can extract the values into a numpy array like this.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['intensity'].values\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["A Series (and DataFrame) are like numpy arrays in some ways, and different in others. Suppose we want to see the first five entries of the intensity. If we want to use *integer-based* indexing like we have so far, you have to use the `iloc` attribute on the series like this. `iloc` is for integer location.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['intensity'].iloc[0:5]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What about the wavenumbers? These are called the *index* of the dataframe.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.index\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can index the index with integers as you can with an array.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.index[0:5]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, you can combine these so that you index a column with a slice of the index like this.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['intensity'][df.index[0:5]]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In summary, we can think of a dataframe as a hybrid array/dictionary where we have an index which is like the independent variable, and a set of columns that are like dependent variables. You can access the columns like a dictionary.\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Dataframes and visualization\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dataframes also provide easy access to [visualization](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html). The simplest method is to just call the plot method on a dataframe. Note this automatically makes the plot with labels and a legend. If there are many columns, you will have a curve for each one of them. We will see that later.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.plot();\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Reading data in Pandas\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's get back to how we got the data into Pandas. Let's retrieve the data file we used before with several columns in it.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fname = 'p-t.dat'\n", "url = 'https://www.itl.nist.gov/div898/handbook/datasets/MODEL-4_4_4.DAT'\n", "\n", "import urllib.request\n", "urllib.request.urlretrieve(url, fname)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Let's refresh our memory of what is in this file:\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["! head p-t.dat\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We use [Pandas.read\\_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to read this, similar to how we used `numpy.loadtxt`. It also takes a lot of arguments to fine-tune the output. We use spaces as the delimiter here. `'\\s+'` is a *regular expression* for multiple spaces. We still skip two rows, and we have to manually define the column names. We *do not* specify an index column here, we get a default one based on integers. Pandas is smart enough to recognize the first two columns are integers, so we do not have to do anything special here.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('p-t.dat', delimiter='\\s+', skiprows=2,\n", "                 names=['Run order', 'Day', 'Ambient Temperature', 'Temperature',\n", "                        'Pressure', 'Fitted Value', 'Residual'])\n", "df\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The default plot is not that nice.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.plot();\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The default is to plot each column vs the index, which is not that helpful for us. Say we just want to plot the pressure vs. the temperature.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.plot(x='Temperature', y='Pressure', style='b.');\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can add multiple plots to a figure, but we have to tell the subsequent calls which axes to put them on. To do that, save the first one, and pass it as an argument in subsequent plots.  That also allows you to fine-tune the plot appearance, e.g. add a y-label. See the [matplotlib documentation](https://matplotlib.org/contents.html) to learn how to set all of these.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["p1 = df.plot(x='Temperature', y='Pressure', style='b.')\n", "df.plot(x='Temperature', y='Fitted Value', ax=p1)\n", "\n", "p1.set_ylabel('values');\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It is a reasonable question to ask if this is simpler than what we did before using arrays, variables and plotting commands. Dataframes are increasingly common in data science, and are the data structure used in many data science/machine learning projects.\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Another real-life example\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["LAMMPS is a molecular simulation code used to run molecular dynamics. It outputs a text file that is somewhat challenging to read. There are variable numbers of time steps that depend on how the simulation was setup.\n", "\n", "Start by downloading and opening this file. It is a molecular dynamics trajectory at constant volume, where the pressure, temperature and energy fluctuate.\n", "\n", "Open this file [log1.lammps](./log1.lammps) to get a sense for what is in it. The data starts around:\n", "\n", "    timestep 0.005\n", "    run ${runSteps}\n", "    run 500000\n", "    Per MPI rank memory allocation (min/avg/max) = 4.427 | 4.427 | 4.427 Mbytes\n", "    Step v_mytime Temp Press Volume PotEng TotEng v_pxy v_pxz v_pyz v_v11 v_v22 v_v33 CPU\n", "           0            0         1025    601.28429    8894.6478   -1566.6216   -1500.5083    2065.6285    1713.4095    203.00499 1.3408976e-05 9.2260011e-06 1.2951038e-07            0 w\n", "\n", "And it ends around this line.\n", "\n", "      500000         2500    978.62359   -2100.7614    8894.6478   -1570.5382   -1507.4162   -252.80665    614.87398    939.65393 0.00045263648 0.00043970796 0.00044228719    1288.0233\n", "    Loop time of 1288.02 on 1 procs for 500000 steps with 500 atoms\n", "\n", "Our job is to figure out where those lines are so we can read them into Pandas. There are many ways to do this, but we will stick with a pure Python way. The strategy is to search for the lines, and keep track of their positions.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start, stop = None, None\n", "with open('log1.lammps') as f:\n", "    for i, line in enumerate(f):\n", "        if line.startswith('Step v_mytime'):\n", "            start = i\n", "        if line.startswith('Loop time of '):\n", "            stop = i - 1  # stop on the previous line\n", "            break\n", "start, stop\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This gets tricky. We want to skip the rows up to the starting line. At that point, the line numbers restart as far as Pandas is concerned, so the header is in line 0 then, and the number of rows to read is defined by the stop line minus the start line. The values are separated by multiple spaces, so we use a *pattern* to indicate multiple spaces. Finally, we prevent the first column from being the index column by setting index\\_col to be False. See [https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html>](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html>)for all the details.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv('log1.lammps', skiprows=start, header=0, nrows=stop - start, delimiter='\\s+', index_col=False)\n", "df\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Visualizing the data\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Plot a column\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The effort was worth it though; look how easy it is to plot the data!\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.plot(x='Step', y='Press');\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "fig, (ax0, ax1) = plt.subplots(1, 2)\n", "df.plot(x='Temp', y='PotEng', style='b.', ax=ax0)\n", "df.plot(x='Press', y='PotEng', style='b.', ax=ax1)\n", "plt.tight_layout()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Plot distributions of a column\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can look at histograms of properties as easily.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.hist('PotEng', xrot=45, bins=20, density=True);\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Plot column correlations\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This is just the beginning of using Pandas. Suppose we want to see which columns are correlated ([https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)). With variables this would be tedious.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.matshow(df.corr());\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can see these correlations with a pairplot. This is moderately expensive to plot (it could take a few minutes).\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import seaborn as sns\n", "sns.pairplot(df);\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can also make the figure manually. Note, it is not possible to plot a column against itself with Pandas (I think this is a bug [https://github.com/pandas-dev/pandas/issues/22088](https://github.com/pandas-dev/pandas/issues/22088)), so here I use matplotlib functions for the plotting. This should be symmetric, so I only plot the upper triangle.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["keys = df.keys()\n", "\n", "fig, axs = plt.subplots(13, 13)\n", "fig.set_size_inches((8, 8))\n", "for i in range(13):\n", "    for j in range(i, 13):\n", "        axs[i, j].plot(df[keys[i]], df[keys[j]], 'b.', ms=2)\n", "        # remove axes so it is easier to read\n", "        axs[i, j].axes.get_xaxis().set_visible(False)\n", "        axs[i, j].axes.get_yaxis().set_visible(False)\n", "        axs[j, i].axes.get_xaxis().set_visible(False)\n", "        axs[j, i].axes.get_yaxis().set_visible(False);\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Getting parts of a Pandas DataFrame\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We have seen how to get a column from a DataFrame like this:\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['Press']\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["In this context, the DataFrame is acting like a dictionary. You can get a few columns by using a list of column names.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[['Press', 'PotEng']]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["What about a row? This is what we would have done with a numpy array, but it just doesn't work here.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[0]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The problem is that as a dictionary, the keys are for the *columns*.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.keys()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["One way to get the rows by their integer index is to use the *integer location* attribute for a row.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.iloc[0]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can use slices on this.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.iloc[0:5]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This example may be a little confusing, because our index does include 0, so we can in this case also use the row label with the *location* attribute. You can use any value in the index for this.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.index\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[0]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can access the first five rows like this.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[0:4]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["And a slice of a column like this.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.loc[0:4, 'Press']\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can access a value in a row and column with the `at` function on a DataFrame.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.at[2, 'Press']\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Or if you know the row and column numbers you can use `iat`.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.iat[2, 3]\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Operating on columns in the DataFrame\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Some functions just work across the columns. For example, DataFrames have statistics functions like this.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.mean()\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We should tread carefully with other functions that work on arrays. For example consider this example that computes the mean of an entire array.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["a = np.array([[1, 1, 1],\n", "              [2, 2, 2]])\n", "np.mean(a)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["It does not do the same thing on a DataFrame. The index and column labels are preserved with numpy functions.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "\n", "np.mean(df) # takes mean along axis 0\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.max(df)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.exp(df)\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["2 * df\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We can apply a function to the DataFrame. The default is the columns (axis=0). Either way, we get a new DataFrame.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def minmax(roworcolumn):\n", "    return np.min(roworcolumn), np.max(roworcolumn)\n", "\n", "df.apply(minmax)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here we analyze across the rows.\n", "\n", "\n", "\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.apply(minmax, axis=1)\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "\n", "\n", "\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Pandas is a multipurpose data science tool. In many ways it is like a numpy array, and in many ways it is different. In some ways it is like a dictionary.\n", "\n", "The similarities include the ability to do some indexing and slicing. This is only a partial similarity though.\n", "\n", "The differences include integrated plotting.\n", "\n", "You should finish reading https://jakevdp.github.io/PythonDataScienceHandbook/03.00-introduction-to-pandas.html.\n", "\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.7"}, "org": null, "widgets": {"application/vnd.jupyter.widget-state+json": {"state": {}, "version_major": 2, "version_minor": 0}}}, "nbformat": 4, "nbformat_minor": 4}